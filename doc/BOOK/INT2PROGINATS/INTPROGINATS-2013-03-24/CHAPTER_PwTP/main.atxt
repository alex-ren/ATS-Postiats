%{
//
dynload
"libatsdoc/dynloadall.dats"
//
#include "./../proginatsatxt.dats"
//
%}\
#comment("\n\
The file is automatically generated by [atsdoc] from main.atxt.\n\
")
#comment("\n\
Time of Generation: #timestamp()\
")
<chapter id="programming_with_theorem-proving">
#title("Programming with Theorem-Proving")

#para("\

#emph("Programming with Theorem-Proving") (PwTP) is a rich and broad
programming paradigm that allows cohesive construction of programs and
proofs in a syntactically intwined manner. The support for PwTP in ATS is a
signatory feature of ATS, and the novelty of ATS largely stems from it. For
people who are familiar with the so-called Curry-Howard isomorphism, I
emphasize that PwTP as is supported in ATS makes little, if any, essential
use of this isomorphism (between proofs and programs): The dynamics of ATS
in which programs are written is certainly not pure and the proofs encoded
in ATS/LF are not required to be constructive, either. However, that proof
construction in ATS can be done in a style of (functional) programming is
fundamentally important in terms of syntax design for ATS, for the need to
combine programs with proofs would otherwise be greatly more challenging.

")

#para("\
In this chapter, I will present some simple but convincing examples to
illustrate the power and flexibility of PwTP as is supported in
ATS. However, the real showcase for PwTP will not arrive until after the
introduction of linear types in ATS, when linear proofs can be combined
with programs to track and safely manipulate resources such as memory and
objects (e.g, file handles). In particular, PwTP is to form the cornersone
of the support for imperative programming in ATS.
")

#para("\
Please find #mycodelink("CHAPTER_PwTP/", "on-line")
the code employed for illustration in this chapter plus some additional
code for testing.\
")

<sect1 id="circumventing_nonlinear_constraints">
#title("Circumventing Nonlinear Constraints")

#para("
The constraint-solver of ATS is of rather diminished power. In particular,
constraints containing nonlinear integer terms (e.g., those involving the
use of multiplication (of variables)) are immediately rejected. This
weakness must be properly addressed for otherwise it would become a
crippling limitation on practicality of the type system of ATS. I now use
a simple example to demonstrate how theorem-proving can be employed to
circumvent the need for handling nonlinear constraints directly.
")#comment("para")

#para("
A function template #code("list_concat") is implemented as follows:

#atscode("\
//
// [list_concat] does not typecheck!!!
//
fun{a:t@ype}
list_concat {m,n:nat}
  (xss: list (list (a, n), m)): list (a, m * n) =
  case+ xss of
  | list_cons (xs, xss) => list_append<a> (xs, list_concat xss)
  | list_nil () => list_nil ()
// end of [list_concat]
")

where the interface for #code("list_append") is given below:

#atscode("\
fun{a:t@ype} list_append {n1,n2:nat}
  (xs: list (a, n1), ys: list (a, n2)): list (a, n1+n2)
")

Given a list #code("xss") of length #code("m") in which each element is of
the type #code("list")(T,n) for some type T,
#code("list_concat&lt;T&gt;(xss)") constructs a list of the type
#code("list(T,m*n)"). When the first matching clause in the code for
#code("list_concat") is typechecked, a constraint is generated that is
essentially like the following one:

#atscode("\
m = m1 + 1 implying n + (m1 * n) = m * n holds for all natural numbers m, m1 and n.
")

This contraint may look simple, but it is rejected by the ATS constraint
solver as it contains nonlinear integer terms (e.g., #code("m1*n") and
#code("m*n")). In order to overcome (or rather circumvent) the limitation,
we make use of theorem-proving. Another implementation of
#code("list_concat") is given as follows:

#atscode("\
fun{a:t@ype}
list_concat {m,n:nat} (
  xss: list (list (a, n), m)
) : [p:nat] (MUL (m, n, p) | list (a, p)) =
  case+ xss of
  | list_cons (xs, xss) => let
      val (pf | res) = list_concat (xss)
    in
      (MULind pf | list_append<a> (xs, res))
    end
  | list_nil () => (MULbas () | list_nil ())
// end of [list_concat]
")

Given a list #code("xss") of the type #code("list(list(T,n),m)"),
#code("list_concat(xss)") now returns a pair #code("(pf | res)")
such that #code("pf") is a
proof of the prop-type #code("MUL(m,n,p)") for some natural number
#code("p") and #code("res") is a list of the type #code("list(T,p)"),
where the symbol bar (|) is used to separate proofs from values. In
other words, #code("pf")
acts as a witness to the equality #code("p=m*n"). After proof erasure is
performed, this implementation of #code("list_concat") is essentially
translated into the previous one (as far as dynamic semantics is
concerned). In particular, there is no proof construction at run-time and
no need for it, either.  ")#comment("para")

</sect1><!--"circumventing_nonlinear_constraints"-->

#comment(" ****** ****** ")

<sect1 id="example_safe_matrix_subscripting">
#title("Example: Safe Matrix Subscripting")

#para("\

Internally, a matrix of the dimension m by n is represented as an array
of the size m*n. For matrix subscripting, we need to implement a function
template of the following interface:

#atscode("\
extern
fun{
a:t@ype
} matget
  {m,n:nat}{i,j:nat | i < m; j < n}
  (A: array (a, m*n), col: int n, i: int i, j: int j): a
// end of [matget]
")

Assume that the matrix is row-major. Then the element indexed by i and j in
the matrix is the element indexed by i*n + j in the array that represents
the matrix, where i and j are natural numbers less than m and n,
respectively. However, the following implementation fails to pass
typechecking:

#atscode("\
implement{a} matget (A, n, i, j) = A[i*n+j] // it fails to typecheck!!!
")#comment("para")

as the ATS constraint solver cannot automatically verify that i*n+j is a
natural number strictly less than m*n. An implementation of #code("matget")
that typechecks can be given as follows:

#atscode("\
implement{a}
matget {m,n} {i,j} (A, n, i, j) = let
//
  val (pf_in | _in) = i imul2 n // pf_in: MUL (i, n, _in)
  prval () = mul_nat_nat_nat (pf_in) // _in >= 0
//
  prval pf_mn = mul_istot {m,n} () // pf1_mn: MUL (m, n, _mn)
  prval () = mul_elim (pf_mn) // _mn = m*n
  prval MULind (pf_m1n) = pf_mn // _m1n = (m-1)*n = m*n-n
//
  stadef i1 = m-1-i
  prval pf_i1n = mul_istot {i1,n} () // pf_i1n: MUL (i1, n, _i1n)
  prval () = mul_nat_nat_nat (pf_i1n) // _i1n >= 0
//
  prval pf2_m1n = mul_distribute2 (pf_in, pf_i1n) // _m1n = _in + _i1n
  prval () = mul_isfun (pf_m1n, pf2_m1n) // _mn - n = _in + _i1n 
//
in
  A[_in+j]
end // end of [matget]
")

where the functions called in the body of #code("matget")
are assigned the following interfaces:

#atscode("\
fun imul2 {i,j:int}
  (i: int i, j: int j): [ij:int] (MUL (i, j, ij) | int ij)

prfun mul_istot {i,j:int} (): [ij:int] MUL (i, j, ij)

prfun mul_isfun {i,j:int} {ij1, ij2: int}
  (pf1: MUL (i, j, ij1), pf2: MUL (i, j, ij2)): [ij1==ij2] void

prfun mul_elim
  {i,j:int} {ij:int} (pf: MUL (i, j, ij)): [i*j==ij] void

prfun mul_nat_nat_nat
  {i,j:nat} {ij:int} (pf: MUL (i, j, ij)): [ij >= 0] void

prfun mul_distribute2
  {i1,i2:int} {j:int} {i1j,i2j:int}
  (pf1: MUL (i1, j, i1j), pf2: MUL (i2, j, i2j)): MUL (i1+i2, j, i1j+i2j)
")

Note that the keyword #code("stadef") is for introducing a binding between
a name and a static term (of any sort).

Assume that m and n are natural numbers and i and j are natural numbers
less than m and n, respectively.
The method employed in the implementation of #code("matget") to show i*n+j
< m*n essentially proves that m*n = (m-1)*n + n, (m-1)*n = i*n + (m-1-i)*n
and (m-1-i)*n >= 0, which in turn imply that m*n >= i*n+n > i*n+j.

")#comment("para")

#para("
Note that there are a variety of proof functions declared in <ulink
url=\"http://www.ats-lang.org/DOCUMENT/ANAIRIATS/prelude/SATS/arith.sats\"><filename>prelude/SATS/arith.sats</filename></ulink>
for helping prove theorems involving arithmetic operations. For examples of
proof construction in ATS, please find the implementation of some of
these proof functions in <ulink
url=\"http://www.ats-lang.org/DOCUMENT/ANAIRIATS/prelude/DATS/arith.dats\"><filename>prelude/DATS/arith.dats</filename></ulink>.
")#comment("para")

#para("
The entirety of the above presented code is available #mycodelink("CHAPTER_PwTP/matget.dats", "on-line").
")#comment("para")

</sect1><!--"example_safe_matrix_subscripting"-->

#comment(" ****** ****** ")

<sect1 id="specifying_with_precision" xreflabel="specifying with enhanced precision">
#title("Specifying with Enhanced Precision")

#para("
The integer addition function can be assigned the following
(dependent) type in ATS to indicate that it returns the sum of
its two integer arguments:

#atscode("\
{i,j:int} (int (i), int (j)) -> int (i+j)
")

This type gives a full specification of integer addition as the only
(terminating) function that can be given the type is the integer addition
function. However, the factorial function, which yields the product of the
first n positive integers when applied to a natural number n, cannot be
given the following type:

#atscode("\
{n:nat} int (n) -> int (fact(n))
")

as #code("fact"), which refers to the factorial function, does not exist in
the statics of ATS. Evidently, a highly interesting and relevant question is
whether a type can be formed in ATS that fully captures the functional
relation specified by #code("fact")? The answer is affirmative. We can not
only construct such a type but also assign it to a (terminating) function
implemented in ATS.
")#comment("para")

#para("\
Let us recall that the factorial function can be defined by the following
two equations:

#atscode("\
fact(0) = 1
fact(n) = n * fact(n-1) (for all n > 0)
")

Naturally, these equations can be encoded by the constructors associated
with the dataprop #code("FACT") declared as follows:

#atscode("\
dataprop FACT (int, int) =
  | FACTbas (0, 1)
  | {n:nat} {r1,r:int} FACTind (n, r) of (FACT (n-1, r1), MUL (n, r1, r))
// end of [FACT]
")

Note that for any given natural number n and integer r, #code("FACT")(n, r)
can be assigned to a proof if and only if #code("fact")(n) = r. Therefore,
the following type

#atscode("\
{n:nat} int (n) -> [r:int] (FACT (n, r) | int (r))
")

can only be assigned to a function that, if applied to a natural number n,
returns a proof and an integer such that the proof attests to the integer
being equal to #code("fact")(n). For instance, the following defined
function #code("ifact") is assigned this type:

#atscode("\
fun ifact {n:nat} .<n>.
  (n: int n): [r:int] (FACT (n, r) | int r) =
  if n > 0 then let
    val (pf1 | r1) = ifact (n-1) // pf1: FACT (n-1, r1)
    val (pfmul | r) = n imul2 r1 // pfmul: FACT (n, r1, r)
  in (
    FACTind (pf1, pfmul) | r
  ) end else (
    FACTbas () | 1 // the base case
  ) // end of [if]
// end of [ifact]
")

After proof erasure, #code("ifact") precisely implements the factorial function.
")#comment("para")

#para("\
Please find the entirety of the above presented code plus some testing code
#mycodelink("CHAPTER_PwTP/ifact.dats", "on-line").
")

</sect1><!--"specifying_with_precision"-->

#comment(" ****** ****** ")

<sect1 id="example_another_verified_factorial">
#title("Example: Another Verified Factorial Implementation")

#para("\

The function #code("ifact") presented in the section on <xref
linkend=\"specifying_with_precision\"/> is a verified implementation of
the factorial function as its type guarantees that #code("ifact")
implements the specification of factorial encoded by the dataprop
#code("FACT"). Clearly, the implementation of #code("ifact") closely
follows the declaration of #code("FACT"). If we think of the latter as a
logic program, then the former is essentially a functional version
extracted from the logic program. However, the implementation of a
specification in practice can often digress far from the specification
algorithmically. For instance, we may want to have a verified
implementation of factorial that is also tail-recursive. This can be done
as follows:

#atscode("\
fun ifact2 {n:nat} .<>.
  (n: int n): [r:int] (FACT (n, r) | int r) = let
  fun loop
    {i:nat | i <= n} {r:int} .<n-i>. (
    pf: FACT (i, r) | n: int n, i: int i, r: int r
  ) : [r:int] (FACT (n, r) | int r) =
    if n - i > 0 then let
      val (pfmul | r1) = (i+1) imul2 r in loop (FACTind (pf, pfmul) | n, i+1, r1)
    end else (pf | r) // end of [if]
  // end of [loop]
in
  loop (FACTbas () | n, 0, 1)
end // end of [ifact2]
")

The function #code("ifact2") is assigned a type indicating that
#code("ifact2") is a verified implementation of factorial, and it is
defined as a call to the inner function #code("loop") that is clearly
tail-recursive.  If we erase types and proofs, the function #code("ifact2")
is essentially defined as follows:

#atscode("\
fun ifact2 (n) = let
  fun loop (n, i, r) =
    if n - i > 0 then let
      val r1 = (i+1) * r in loop (n, i+1, r1)
    end else r
  // end of [loop]
in
  loop (n, 0, 1)
end // end of [ifact2]
")

When the inner function #code("loop") is called on three arguments n, i and
r, the precondition for this call is that i is natural number less than or
equal to n and r equals #code("fact")(i), that is, the value of the
factorial function on i. This precondition is captured by the type assigned
to #code("loop") and thus enforced at each call site of #code("loop") in
the implementation of #code("ifact2").

")#comment("para")

#ignore("\
#para("\
#atscode("\
fun ifact3 {n:nat} .<>.
  (n: int n): [r:int] (FACT (n, r) | int r) = let
//
extern prfun
lemma {p,q:int} {r:int} (): [qr:int | (p*q)*r==p*(qr)] MUL (q, r, qr)
//
  fun loop
    {n:nat} {r0:int} .<n>. (
    n: int n, r0: int r0
  ) : [r:int] (FACT (n, r) | int (r0*r)) =
    if n > 0 then let
      val [r1:int] (pf1 | res) = loop (n-1, r0*n) // pf1: FACT(n-1, r1); res = (r0*n)*r1
      prval pfmul = lemma {r0,n} {r1} () // pfmul: MUL (n, r1, r); res = r0*r for some r
    in (
      FACTind (pf1, pfmul) | res
    ) end else (
      FACTbas () | r0
    ) // end of [if]
in
  loop (n, 1)
end // end of [ifact3]
")
")#comment("para")
")#comment("ignore")

#para("\
Please find #mycodelink("CHAPTER_PwTP/ifact23.dats", "on-line")
the entirety of the above presented code plus some testing code.
")

</sect1><!--"example_another_verified_factorial"-->

#comment(" ****** ****** ")

<sect1 id="example_verified_fast_exponentiation">
#title("Example: Verified Fast Exponentiation")

#para("\
Given an integer x, #code("pow")(x, n), the nth power of x, can be defined
inductively as follows:

#atscode("\
pow (x, 0) = 1
pow (x, n) = x * pow (x, n-1) (for all n > 0)
")

A direct implementation of this definition is given as follows:

#atscode("\
fun ipow {n:nat} .<n>.
  (x: int, n: int n): int = if n > 0 then x * ipow (x, n-1) else 1
// end of [ipow]
")

which is of time-complexity O(n) (assuming multiplication is O(1)). A
more efficient implmentation can be given as follows:

#atscode("\
fun ifastpow {n:nat} .<n>.
  (x: int, n: int n): int =
  if n > 0 then let
    val n2 = n/2; i = n-(2*n2)
  in
    if i > 0 then pow (x*x, n2) else x * pow (x*x, n2)
  end else 1
// end of [ifastpow]
")

which makes use of the property that #code("pow")(x, n) equals
#code("pow")(x*x, n/2) if n is even or x * #code("pow")(x*x, n/2) if n is
odd. This is referred to as fast exponentiation. Note that
#code("ifastpow") is of time-complexity O(log(n)).

")#comment("para")

#para("\

Clearly, what is done above is not restricted to exponentiation on
integers. As long as the underlying multiplication is associative, fast
exponentiation can be employed to compute powers of any given element. In
particular, powers of square matrices can be computed in this way.  I now
present as follows a verified generic implementation of fast exponentiation.

")#comment("para")

#para("\
Handling generic data properly in a verified implementation often requires some
finesse with the type system of ATS. Let us first introduce an abstract type
constructor #code("E") as follows:

#atscode("\
sortdef elt = int // [elt] is just an alias for [int]
abst@ype E (a:t@ype, x:elt) = a // [x] is an imaginary stamp
")

This is often referred to as #emph("stamping"). For each type T and stamp
x, #code("E")(T, x) is just T as far as data representation is concerned.
The stamps are imaginary and they are solely used for the purpose of
specification. We next introduce an abstract prop-type #code("MUL") and
a function template #code("mul_elt_elt"):

#atscode("\
absprop MUL (elt, elt, elt) // abstract mul relation

fun{a:t@ype}
mul_elt_elt {x,y:elt}
  (x: E (a, x), y: E (a, y)): [xy:elt] (MUL (x, y, xy) | E (a, xy))
// end of [mul_elt_elt]
")

Please do not confuse #code("MUL") with the one of the same name
that is declared in #myatscodelink("prelude/SATS/arith.sats",
"prelude/SATS/arith.sats"). To state that the encoded multiplication
is associative, we can introduce the following proof function:

#atscode("\
praxi mul_assoc
  {x,y,z:elt} {xy,yz:elt} {xy_z,x_yz:elt} (
  pf1: MUL (x, y, xy), pf2: MUL (xy, z, xy_z)
, pf3: MUL (y, z, yz), pf4: MUL (x, yz, x_yz)
) : [xy_z==x_yz] void
")

The keyword #code("praxi") indicates that #code("mul_assoc") is treated as
a form of axiom, which is not expected to be implemented.

")#comment("para")

#para("
The abstract power function can be readily specified in terms of the
abstract prop-type #code("MUL"):

#atscode("\
dataprop POW (
  elt(*base*), int(*exp*), elt(*res*)
) = // res = base^exp
  | {x:elt} POWbas (x, 0, 1(*unit*))
  | {x:elt} {n:nat} {p,p1:elt}
    POWind (x, n+1, p1) of (POW (x, n, p), MUL (x, p, p1))
// end of [POW]
")

As can be expected, generic fast exponentiation is given the following
interface:

#atscode("\
fun{a:t@ype}
fastpow_elt_int {x:elt} {n:nat}
  (x: E (a, x), n: int n): [p:elt] (POW (x, n, p) | E (a, p))
// end of [fastpow_elt_int]
")

")#comment("para")

#para("
With the preparation done above, a straightforward implementation of
#code("fastpow_elt_int") can now be presented as follows:

#atscode("\
implement{a}
fastpow_elt_int (x, n) = let
//
// lemma: (x*x)^n = x^(2n)
//
extern prfun
lemma {x:elt} {xx:elt} {n:nat} {y:elt}
  (pfxx: MUL (x, x, xx), pfpow: POW (xx, n, y)): POW (x, 2*n, y)
//
in
  if n > 0 then let
    val n2 = n / 2; val i = n - (n2+n2) // i = 0 or 1
    val (pfxx | xx) = mul_elt_elt (x, x) // xx = x*x
    val (pfpow2 | res) = fastpow_elt_int<a> (xx, n2) // xx^n2 = res
    prval pfpow = lemma (pfxx, pfpow2) // pfpow: x^(2*n2) = res
  in
    if i > 0 then let
      val (pfmul | xres) = mul_elt_elt<a> (x, res) // xres = x*res
    in
      (POWind (pfpow, pfmul) | xres)
    end else (pfpow | res)
  end else let
    val res = mulunit<a> () in (POWbas () | res) // res = 1
  end (* end of [if] *)
end // end of [fastpow_elt_int]
")

Note that this implementation of #code("fastpow_elt_int") is not
tail-recursive.  The function template #code("mulunit"), which is called to
produce a unit for the underlying multiplication, is assigned the following
interface:

#atscode("\
fun{a:t@ype} mulunit (): E (a, 1(*stamp*))
")

The proof function #code("lemma") simply establishes that #code("pow")(x,
2*n)=#code("pow")(x*x, n) for each natural number n.  I have made an
implementation of #code("lemma") available on-line but I suggest that the
interested reader give it a try first before taking a look. Note that the
following axioms are needed to implement #code("lemma"):

#atscode("\
praxi mul_istot // [MUL] is total
  {x,y:elt} (): [xy:elt] MUL (x, y, xy)
praxi mul_isfun {x,y:elt} {z1,z2:elt} // MUL is functional
  (pf1: MUL (x, y, z1), pf2: MUL (x, y, z2)): [z1==z2] void
")

Another interesting (and possibly a bit challenging) exercise is to
implement #code("fastpow_elt_int") in a tail-recursive fashion.

")#comment("para")

#para("\
Please find on-line the two files
#mycodelink("CHAPTER_PwTP/fastexp.sats", "fastexp.sats") and
#mycodelink("CHAPTER_PwTP/fastexp.dats", "fastexp.dats") that contain the
entirety of the above presented code.
")

#para("\

Now we have implemented #code("fastpow_elt_int"). How can we use it? Please
find #mycodelink("CHAPTER_PwTP/test_fastexp.dats", "on-line") an example in
which #code("fastpow_elt_int") is called to implement fast exponentiation
on a 2-by-2 matrix so that Fibonacci numbers can be computed in a highly
efficient manner.

")

</sect1><!--"example_verified_fast_exponentiation"-->

</chapter><!--"programming_with_theorem-proving"-->

#comment(" ****** ****** ")

#comment(" end of [main.atxt] ")

%{
implement main () = fprint_filsub (stdout_ref, "main_atxt.txt")
%}
